# ============================================================
# üéì QWEN 3 32B - BALANCED TRAINING V4 (NAHUATL)
# ============================================================
# Configuraci√≥n: Transformers + PEFT + RSLoRA + Dual T4 + W&B
# Dataset: 70k Balanceado (59k Gold + 11k DPO sobremuestreado 10x)
# Kaggle GPU: T4 x2 (30GB VRAM Total)
# Modelo: 32B Parameters (High Reasoning Tier)
import os
import subprocess
import sys

# üöÄ ACTUALIZACI√ìN CR√çTICA: Forzar versiones SOTA para evitar conflictos de API
print("üì¶ Actualizando librer√≠as cr√≠ticas...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "-U", "trl", "transformers", "accelerate", "peft", "bitsandbytes"])

# üî• FIX NUCLEAR PROTOBUF: Debe estar al inicio absoluto
os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'

# üíæ FIX DISCO: Redirigir cach√© a /kaggle/working
os.environ['HF_HOME'] = '/kaggle/working/hf_cache'
os.makedirs('/kaggle/working/hf_cache', exist_ok=True)

# üß† FIX VRAM: Prevenir fragmentaci√≥n agresiva
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import torch
import pandas as pd
import wandb
from datasets import Dataset
from huggingface_hub import login
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer, 
    BitsAndBytesConfig, 
    TrainingArguments,
    DataCollatorForSeq2Seq
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from trl import SFTTrainer, SFTConfig
from kaggle_secrets import UserSecretsClient

# 1. Autenticaci√≥n y Rutas
user_secrets = UserSecretsClient()

# Login Hugging Face
hf_token = user_secrets.get_secret("hf_token")
login(token=hf_token)

# Login W&B
os.environ["WANDB_API_KEY"] = user_secrets.get_secret("wandb_api_key")
wandb.init(project="qwen3-nahuatl-balanced-v4", name="run-balanced-70k-opcionD")

# üîç DETECCI√ìN DE MODELO (Kaggle Models vs Hugging Face)
MODEL_ID = "Qwen/Qwen3-32B"
LOCAL_PATH = "/kaggle/input/qwen-3/transformers/32b/1"
if os.path.exists(LOCAL_PATH):
    print(f"‚úÖ Detectado modelo local en: {LOCAL_PATH}")
    MODEL_ID = LOCAL_PATH
else:
    print(f"‚ö†Ô∏è No se detect√≥ modelo en /kaggle/input. Se intentar√° descargar de HF (¬°Cuidado con el espacio!)")

# üéØ DATASET BALANCEADO V4 (70k: 59k Gold + 11k DPO 10x)
DATA_PATH = "/kaggle/input/nahuatl-balanced-corpus-70k/train_balanced_v2.parquet"

# üîÑ CHECKPOINT ANTERIOR (Opcional - para continuar desde checkpoint 800)
RESUME_FROM_CHECKPOINT = None
CHECKPOINT_PATH = "/kaggle/input/nawatl-qwen3-checkpoint-800/checkpoint-800"
if os.path.exists(CHECKPOINT_PATH):
    print(f"‚úÖ Detectado checkpoint anterior: {CHECKPOINT_PATH}")
    print("‚ö†Ô∏è  Para continuar desde este checkpoint, descomenta la l√≠nea siguiente:")
    # RESUME_FROM_CHECKPOINT = CHECKPOINT_PATH
else:
    print("‚ÑπÔ∏è  No se detect√≥ checkpoint anterior. Entrenando desde modelo base.")

OUTPUT_DIR = "./qwen3-32b-nawatl-balanced-v4"

# 2. Configuraci√≥n Cuantizaci√≥n 4-bit (Cr√≠tico para 32B en T4)
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16, # Turing prefiere fp16 sobre bf16
    bnb_4bit_use_double_quant=True,
    llm_int8_enable_fp32_cpu_offload=True,  # üî• CR√çTICO: Permite offload a CPU si es necesario
)

# üßπ LIMPIEZA PRE-CARGA (Cr√≠tico para Dual T4)
import gc
gc.collect()
torch.cuda.empty_cache()

# ‚öñÔ∏è Mapa de Memoria Expl√≠cito (Para 32B en 2x T4 de 15GB)
# Ajustado para ser m√°s conservador y permitir offload sin errores
max_memory = {
    0: "13GiB",  # GPU 0
    1: "13GiB",  # GPU 1  
    "cpu": "30GiB"  # üî• CR√çTICO: Permitir offload a CPU si es necesario
}

# 3. Cargar Tokenizer y Modelo
print("üöÄ Cargando Gigante Qwen 3 32B...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"

model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    quantization_config=bnb_config,
    device_map="auto",  # Deja que Accelerate optimice la distribuci√≥n
    max_memory=max_memory,
    trust_remote_code=True,
    torch_dtype=torch.float16,  # üî• Usar torch_dtype en lugar de dtype
    low_cpu_mem_usage=True,
    offload_folder="offload",  # üî• Carpeta para offload temporal
)
model.config.torch_dtype = torch.float16 # Asegurar que la config reporte float16
model = prepare_model_for_kbit_training(model)

# üî• FIX NUCLEAR: Eliminar CUALQUIER rastro de BFloat16 en capas no cuantizadas
print("üßπ Limpiando tipos de datos (BFloat16 -> Float16) en capas compatibles (Deep Sea Purge)...")

# 1. Forzar conversi√≥n de m√≥dulos espec√≠ficos propensos a quedarse en BF16
for name, module in model.named_modules():
    if any(kw in name.lower() for kw in ["norm", "emb", "ln", "head"]):
        module.to(torch.float16)

# 2. Conversi√≥n recursiva de par√°metros y buffers restantes
for name, param in model.named_parameters():
    if param.dtype == torch.bfloat16:
        param.data = param.data.to(torch.float16)

for name, buf in model.named_buffers():
    if buf.dtype == torch.bfloat16:
        buf.data = buf.data.to(torch.float16)

# 3. Asegurar que la configuraci√≥n del modelo est√© alineada
model.config.torch_dtype = torch.float16
print("‚úÖ Purga completada. Tipos de datos alineados con FP16.")

# 4. Configuraci√≥n RSLoRA (No envolver manualmente para evitar merge_and_unload)
peft_config = LoraConfig(
    r=16, # Reducci√≥n extrema para optimizar VRAM de estados AdamW
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    use_rslora=True,
)

# 5. Pipeline de Datos
def formatting_prompts_func(example):
    return f"<|im_start|>user\nTraduce al N√°huatl Cl√°sico:\n{example['es']}<|im_end|>\n<|im_start|>assistant\n{example['nah']}<|im_end|>"

print(f"üìä Cargando Dataset Balanceado V4 desde: {DATA_PATH}")
df = pd.read_parquet(DATA_PATH)
print(f"   ‚úÖ {len(df):,} ejemplos cargados")
print(f"   üìà Composici√≥n aproximada: 84% Gold + 16% DPO (10x oversampled)")

dataset = Dataset.from_pandas(df)

# 6. Argumentos de Entrenamiento - OPCI√ìN D OPTIMIZADA üéØ
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    
    # üî• CAMBIOS OPCI√ìN D
    learning_rate=2e-5,  # ‚¨áÔ∏è Reducido de 3e-5 (m√°s conservador)
    num_train_epochs=2,   # ‚¨áÔ∏è Reducido de 3 (balance tiempo/calidad)
    
    lr_scheduler_type="cosine",
    warmup_ratio=0.1,
    
    # üìä LOGGING Y CHECKPOINTS
    logging_steps=10,  # ‚¨ÜÔ∏è M√°s frecuente para monitoreo
    save_strategy="steps",
    save_steps=50,  # üö® CR√çTICO: Cada 50 pasos para sesiones 12h (antes: 200)
    save_total_limit=3,  # ‚¨áÔ∏è Solo √∫ltimos 3 checkpoints (antes: 5)
    
    # üî• FIX SINERGIA T4: Desactivamos AMP (fp16/bf16) del Trainer para evitar el GradScaler.
    # El modelo sigue usando float16 para c√≥mputo gracias a BitsAndBytesConfig(bnb_4bit_compute_dtype).
    fp16=False, 
    bf16=False,
    
    optim="paged_adamw_8bit",
    report_to="wandb",
    gradient_checkpointing=True,
    gradient_checkpointing_kwargs={"use_reentrant": False}, # Estabilidad adicional
    neftune_noise_alpha=5,
    
    # üîÑ RESUME FROM CHECKPOINT (si est√° configurado)
    resume_from_checkpoint=RESUME_FROM_CHECKPOINT,
)

# Logs de configuraci√≥n
print("\n" + "="*60)
print("‚öôÔ∏è  CONFIGURACI√ìN DE ENTRENAMIENTO V4")
print("="*60)
print(f"üìÇ Dataset: {len(df):,} ejemplos")
print(f"üéì √âpocas: {training_args.num_train_epochs}")
print(f"üìà Learning Rate: {training_args.learning_rate}")
print(f"üíæ Checkpoints cada: {training_args.save_steps} steps")
print(f"üîÑ Resume desde: {RESUME_FROM_CHECKPOINT if RESUME_FROM_CHECKPOINT else 'Modelo base'}")
print(f"‚è±Ô∏è  Steps por √©poca: ~{len(df) // training_args.gradient_accumulation_steps:,}")
print(f"‚è±Ô∏è  Steps totales: ~{(len(df) // training_args.gradient_accumulation_steps) * training_args.num_train_epochs:,}")
print("="*60 + "\n")

# 7. Inicializar Trainer con Inspecci√≥n Total (Defensa de Grado Doctoral)
print("üõ†Ô∏è Configurando SFTTrainer con inspecci√≥n din√°mica...")
import inspect
from trl import SFTTrainer

# Par√°metros potenciales
potential_kwargs = {
    "model": model,
    "train_dataset": dataset,
    "peft_config": peft_config,
    "formatting_func": formatting_prompts_func,
    "args": training_args,
    "max_seq_length": 256, # L√≠mite de seguridad para 32B en T4
    "tokenizer": tokenizer,
    "processing_class": tokenizer, # Nuevo nombre en TRL 0.12+
}

# Obtener firma del SFTTrainer
sig = inspect.signature(SFTTrainer.__init__)
valid_params = sig.parameters.keys()

# Construir kwargs finales solo con lo que el Trainer acepte
trainer_kwargs = {k: v for k, v in potential_kwargs.items() if k in valid_params}

# Logs de depuraci√≥n para el usuario
print(f"‚úÖ Par√°metros aceptados por tu versi√≥n de TRL: {list(trainer_kwargs.keys())}")

# üßπ LIMPIEZA PRE-ENTRENAMIENTO (Cr√≠tico para 32B)
import gc
gc.collect()
torch.cuda.empty_cache()

# Inicializaci√≥n final
trainer = SFTTrainer(**trainer_kwargs)

# 8. ¬°INICIAR ENTRENAMIENTO!
print("\n" + "üî•"*30)
print("üî• INICIANDO ENTRENAMIENTO V4 - OPCI√ìN D BALANCEADA")
print("üî•"*30 + "\n")
print("üìä Monitoreo en tiempo real:")
print(f"   W&B: https://wandb.ai/{wandb.run.entity}/{wandb.run.project}")
print(f"   Checkpoints: {OUTPUT_DIR}/checkpoint-XXXX")
print("\n‚è∞ Recuerda: Kaggle tiene l√≠mite de 12h. Descarga checkpoints peri√≥dicamente.\n")

trainer.train()

# 9. Finalizar
print("\n" + "="*60)
print("‚úÖ ENTRENAMIENTO COMPLETADO")
print("="*60)
print("üíæ Guardando adaptadores finales...")

trainer.model.save_pretrained(f"{OUTPUT_DIR}_final")
tokenizer.save_pretrained(f"{OUTPUT_DIR}_final")

print(f"üìÇ Modelo guardado en: {OUTPUT_DIR}_final")
print(f"üìä Logs W&B: https://wandb.ai/{wandb.run.entity}/{wandb.run.project}")
print("\nüéØ Pr√≥ximos pasos:")
print("   1. Descargar checkpoint final como ZIP")
print("   2. Ejecutar benchmark V8 para validar CHRF >50")
print("   3. Si necesitas continuar, sube checkpoint como dataset")
print("="*60)

wandb.finish()
