# üèõÔ∏è CORC-NAH: Enterprise Data Pipeline para Lenguas Ind√≠genas

> **Arquitectura ETL de Producci√≥n** | Corpus Multiling√ºe (N√°huatl/Maya/Espa√±ol) | Medallion Architecture | Data Quality Automation

[![CI/CD Pipeline](https://github.com/said-moreno/corc-nah-enterprise/workflows/CI%2FCD%20Pipeline/badge.svg)](https://github.com/said-moreno/corc-nah-enterprise/actions)
[![codecov](https://codecov.io/gh/said-moreno/corc-nah-enterprise/branch/main/graph/badge.svg)](https://codecov.io/gh/said-moreno/corc-nah-enterprise)
[![Python 3.9+](https://img.shields.io/badge/python-3.9%20%7C%203.10%20%7C%203.11-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Great Expectations](https://img.shields.io/badge/data%20quality-Great%20Expectations-green.svg)](https://greatexpectations.io/)
[![Tests](https://img.shields.io/badge/tests-116%20passing-brightgreen.svg)](tests/)
[![Last Commit](https://img.shields.io/github/last-commit/said-moreno/corc-nah-enterprise)](https://github.com/said-moreno/corc-nah-enterprise/commits/main)

---

## üéØ Portfolio Data Engineering

Este repositorio demuestra competencias t√©cnicas para **Data Engineer** en entornos enterprise:

| Competencia | Implementaci√≥n | Evidencia |
|-------------|----------------|-----------|
| **ETL Modular** | Arquitectura Bronze/Silver/Diamond/Gold con separation of concerns | [`src/pipeline/`](src/pipeline/), 116 tests ‚úÖ |
| **Data Quality** | Great Expectations (8 validaciones corpus-specific) | [`great_expectations/`](great_expectations/) |
| **CI/CD** | GitHub Actions multi-version + Jenkins declarativo | [`.github/workflows/ci.yml`](.github/workflows/ci.yml) |
| **Orquestaci√≥n** | Control-M simulation + Makefile automation | [`Jenkinsfile`](Jenkinsfile), [ADR 004](docs/adr/004-orchestration-control-m-vs-airflow.md) |
| **SQL Anal√≠tico** | Metadata store con queries de lineage/quality | [`sql/queries/*.sql`](sql/queries/) |
| **Observabilidad** | Structured logging (JSON) + metrics tracking | [`src/utils/logger.py`](src/utils/logger.py) |
| **Testing** | Unit + Integration + Parity tests (>80% coverage) | [`tests/`](tests/) |
| **Documentation** | ADRs documenting architectural decisions | [`docs/adr/`](docs/adr/) |

üìå **Creado para aplicar a:** Bluetab - Data Engineer Position (Enero 2026)

---

## üöÄ Quick Demo (3 minutos)

### Prerequisitos
```bash
# Verificar versi√≥n Python
python --version  # Debe ser 3.9, 3.10, o 3.11

# Docker (opcional, para testing completo)
docker --version
```

### Instalaci√≥n Express
```bash
# 1. Clonar repositorio
git clone https://github.com/said-moreno/corc-nah-enterprise.git
cd corc-nah-enterprise

# 2. Setup autom√°tico (crea venv + instala deps)
make install

# 3. Validar instalaci√≥n
make test
```

**Output esperado:**
```
======================= 116 passed, 15 skipped in 2.36s =======================
‚úÖ Pipeline listo para ejecutar
```

### Ver Pipeline en Acci√≥n

#### Opci√≥n 1: ETL Refactorizado (Production-Ready)
```bash
# Ejecutar pipeline completo con CLI
python -m src.pipeline.cli run

# Ver progreso con barra de loading
# [1/5] Loading Silver layer...  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100%
# [2/5] Loading Diamond layer... ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100%
# [3/5] Normalizing records...   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100%
# [4/5] Splitting into train/val/test...
# [5/5] Saving to Gold layer...  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100%
# ‚úÖ Pipeline Complete (4.2s)
```

#### Opci√≥n 2: Validar Calidad de Datos
```bash
# Ejecutar suite Great Expectations
python scripts/run_quality_check.py data/gold/train_v1.jsonl

# Output:
# ‚úÖ Schema validation PASSED
# ‚úÖ Null checks PASSED
# ‚úÖ Unicode preservation (macrons) PASSED (32% records with ƒÅ/ƒì/ƒ´/≈ç/≈´)
# ‚ö†Ô∏è  Duplicate detection PASSED (98.7% unique - see ADR for rationale)
# ‚úÖ Length constraints PASSED
# ‚úÖ Source validation PASSED
# ‚úÖ Volume sanity check PASSED (1.4M records)
#
# HTML Report: great_expectations/uncommitted/data_docs/local_site/index.html
```

#### Opci√≥n 3: Comparar con Pipeline Legacy (Shadow Mode)
```bash
# Ejecutar tests de paridad (valida que refactored == legacy)
pytest tests/integration/test_parity_with_legacy.py -v

# Ver m√©tricas comparativas
make benchmark
```

---

## üèóÔ∏è Decisiones de Arquitectura

Este proyecto NO es un prototipo acad√©mico, es un **caso de estudio de Data Engineering enterprise-grade**:

### Principios de Dise√±o

1. **Separation of Concerns**
   - **Extractors:** Abstracci√≥n de fuentes (HuggingFace, YouTube, PDFs)
   - **Transformers:** Normalizaci√≥n Unicode, deduplicaci√≥n fuzzy (desacoplados)
   - **Loaders:** Writers con retry logic y checkpointing
   - **Benefit:** Cada componente es testeable en aislamiento

2. **Fail-Fast Philosophy**
   - **Bronze:** Validaci√≥n de schema b√°sica (JSON v√°lido, encoding UTF-8)
   - **Silver:** Quality gates (nulls, duplicates, text length)
   - **Diamond:** Validaciones avanzadas (Unicode preservation, source catalog)
   - **Gold:** Final checks antes de entregar a ML team
   - **Benefit:** Errores detectados temprano, no propagan downstream

3. **Observability First**
   - **Structured Logging:** JSON format (compatible con ELK, CloudWatch)
   - **Trace IDs:** Tracking de registros individuales a trav√©s de capas
   - **Metrics:** Prometheus-ready (duration, throughput, error rates)
   - **Benefit:** Debugging de producci√≥n es trivial, no "black box"

4. **Test-Driven Development**
   - **Unit Tests:** 88 tests (transforms, utils, models)
   - **Integration Tests:** 24 tests (shadow mode, end-to-end)
   - **Parity Tests:** 15 tests (refactored vs legacy comparison)
   - **Coverage:** 80%+ (cr√≠tico para confianza en refactoring)
   - **Benefit:** Refactoring seguro, sin romper funcionalidad existente

5. **Documentation as Code**
   - **ADRs (Architecture Decision Records):** Documentan el "por qu√©", no solo el "qu√©"
   - **Inline Comments:** Explican trade-offs y limitaciones conocidas
   - **Type Hints:** Python 3.9+ annotations para autocomplete
   - **Benefit:** Onboarding de nuevos devs en horas, no d√≠as

### Trade-offs Conscientes

Este proyecto hace elecciones t√©cnicas deliberadas, optimizando para **demo portfolio** vs **producci√≥n enterprise**:

- Modern:  _kuali tonali_
- Huasteca: _kuale tunal_

Our deduplication uses:
- Lowercase + strip whitespace
- Composite keys: `es + nah + myn`
- Layer prioritization: Diamond > Silver

```python
df['dedup_key'] = (
    df['es'].str.lower().str.strip() + "_" +
    df['nah'].fillna('').str.lower().str.strip()
)
df = df.drop_duplicates(subset='dedup_key', keep='last')  # Keep Diamond
```

### 3. Data Quality Validation

Using **Great Expectations** to enforce:
- Null rate < 10% for critical columns
- Duplicate rate < 5%
- Text length distributions (detect corrupted data)
- Unicode character preservation

```bash
great_expectations checkpoint run gold_dataset_validation
```

---

## üß™ Testing Strategy

### Test Pyramid

```
        /\
       /  \        E2E (manual smoke tests)
      /    \
     /------\      Integration (15+ parity tests)
    /        \
   /----------\    Unit (50+ tests, >90% coverage)
```

### Running Tests

```bash
# All tests
make test

# Parity tests only (CRITICAL)
make test-parity

# Unit tests
make test-unit

# Coverage report
make coverage
```

### Parity Test Examples

```python
def test_record_count_parity(golden_stats, golden_train_df):
    """New pipeline must produce exact same record count."""
    expected = golden_stats['train']['total_records']
    actual = len(golden_train_df)
    assert actual == expected

def test_unicode_preservation(golden_stats, golden_train_df):
    """Macrons MUST be preserved (zero tolerance)."""
    text = ''.join(golden_train_df['nah'].dropna())
    assert 'ƒÅ' in text  # Macron must exist
    assert 'ƒì' in text
```

---

## üìà Data Quality Metrics

Current dataset statistics (v1):

| Metric | Value |
|--------|-------|
| Total Records | ~250,000 |
| N√°huatl Pairs | ~180,000 (72%) |
| Maya Pairs | ~70,000 (28%) |
| Duplicate Rate | 2.3% |
| Null Rate (Spanish) | 0.1% |
| Null Rate (Indigenous) | 0.5% |
| Macron Preservation | 100% ‚úÖ |

View full report:
```bash
cat benchmark/golden_stats.json | jq
```

---

## üõ†Ô∏è Development Workflow

### 1. Before Making Changes

```bash
# Ensure golden dataset exists
make golden

# Verify baseline passes
make parity
```

### 2. During Refactoring

```bash
# Format code
make format

# Run tests continuously
pytest-watch tests/

# Check coverage
make coverage
```

### 3. Before Committing

```bash
# Run all quality checks
make check

# Verify parity still passes
make parity
```

---

## üèóÔ∏è Architecture Decisions

We document **WHY** decisions were made using ADRs (Architectural Decision Records):

- [ADR-001: Why SQLite for Metadata](docs/adr/001-why-sqlite.md)
- [ADR-002: Unicode Normalization Strategy](docs/adr/002-unicode-normalization.md)
- [ADR-003: When to Use Spark vs Pandas](docs/adr/003-spark-evaluation.md)

**Key Principle:** We prioritize **understanding** over deployment. The Spark example code demonstrates knowledge of distributed systems without requiring a cluster.

---

## üîÑ CI/CD Pipeline

### GitHub Actions

```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # CRITICAL: Run parity tests
      - name: Parity Tests
        run: make parity

      - name: Unit Tests
        run: make test-unit

      - name: Data Quality
        run: |
          great_expectations checkpoint run gold_validation
```

### Jenkinsfile (Template)

```groovy
// Declarative pipeline showing understanding of Jenkins
pipeline {
    agent any

    stages {
        stage('Setup') {
            steps {
                sh 'make install-dev'
            }
        }

        stage('Parity Tests') {
            steps {
                sh 'make parity'
            }
        }

        stage('Quality Gates') {
            steps {
                sh 'make check'
            }
        }
    }
}
```

---

## üìö Documentation

- **Setup Guide:** [docs/setup-windows.md](docs/setup-windows.md)
- **Architecture:** [docs/architecture.md](docs/architecture.md)
- **ADRs:** [docs/adr/](docs/adr/)
- **API Docs:** [docs/api/](docs/api/)

---

## ü§ù Contributing

This project demonstrates professional software engineering practices:

1. **Never break the golden dataset** - Parity tests MUST pass
2. **Document decisions** - Write ADRs for architectural choices
3. **Type everything** - Use Python type hints + mypy
4. **Test everything** - Maintain >90% coverage

```bash
# Before submitting PR
make check
make parity
```

---

## üìä Metrics & Observability

### Logging

Structured JSON logging for easy parsing:

```python
logger.info(
    "etl_step_completed",
    extra={
        "step": "deduplication",
        "records_before": 100000,
        "records_after": 95000,
        "duplicate_rate": 0.05,
        "duration_seconds": 12.5
    }
)
```

### Metrics

Track pipeline performance:

```bash
# View processing stats
sqlite3 logs/metrics.db "SELECT * FROM pipeline_runs ORDER BY timestamp DESC LIMIT 10"
```

---

## üéì Learning Resources

This project demonstrates understanding of:

- **Data Engineering:** Bronze/Silver/Gold lakehouse, ETL patterns
- **Data Quality:** Great Expectations, regression testing, unicode handling
- **Software Engineering:** Type hints, testing pyramid, CI/CD
- **Big Data:** When to use Spark vs Pandas (see [docs/adr/003-spark-evaluation.md](docs/adr/003-spark-evaluation.md))

**Related Technologies (shown via templates/examples):**
- Apache Spark (see `src/spark_examples/`)
- AWS services (see `docs/aws-architecture.md`)
- Jenkins (see `Jenkinsfile`)
- Control-M (see `docs/controlm-integration.md`)

---

## üìù License

MIT License - see [LICENSE](LICENSE)

---

## üôè Acknowledgments

- **Data Sources:** HuggingFace (AmericasNLP, Flores), YouTube (The N√°huatl Channel), Bible.is
- **N√°huatl Language Resources:** INALI (Instituto Nacional de Lenguas Ind√≠genas)
- **Inspiration:** [Py-Elotl](https://github.com/ElotlMX/py-elotl), [Axolotl NLP](https://github.com/axolotl-ai-cloud/axolotl)

---

## üìß Contact

**Said Moreno** - Data Engineer
LinkedIn: [Said Moreno](https://linkedin.com/in/said-moreno)
Email: said.moreno@email.com

---

**Built with ‚ù§Ô∏è for the N√°huatl and Maya communities**
